{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ensemble Retriever"
      ],
      "metadata": {
        "id": "dzzE7P7rq8nz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-k_QP1RHqgiH"
      },
      "outputs": [],
      "source": [
        "!pip install chromadb tiktoken transformers sentence_transformers openai langchain tablib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_community"
      ],
      "metadata": {
        "id": "7TnlOZIVq7xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "os.environ[\"OPENAI_API_KEY\"] = \" \""
      ],
      "metadata": {
        "id": "jcAmNARHrmSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "#텍스트 토큰으로 분할\n",
        "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "#토큰 수\n",
        "def tiktoken_len(text):\n",
        "    tokens = tokenizer.encode(text)\n",
        "    return len(tokens)"
      ],
      "metadata": {
        "id": "hbNphiB2rqEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import CSVLoader"
      ],
      "metadata": {
        "id": "EoQrOeZnsCZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = CSVLoader(file_path=\" \")\n",
        "documents = loader.load()\n",
        "pages = loader.load_and_split()"
      ],
      "metadata": {
        "id": "GkmwGv5msMLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#page별로 split\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50, length_function = tiktoken_len)\n",
        "texts = text_splitter.split_documents(pages)\n",
        "\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "#허깅페이스 모델을 이용해 임베딩 벡터로 변환\n",
        "model_name = \"jhgan/ko-sbert-nli\"\n",
        "model_kwargs = {'device': 'cpu'}\n",
        "encode_kwargs = {'normalize_embeddings': True}\n",
        "hf = HuggingFaceEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs=model_kwargs,\n",
        "    encode_kwargs=encode_kwargs\n",
        ")\n",
        "\n",
        "#Chroma Vectorstore에 저장\n",
        "docsearch = Chroma.from_documents(texts, hf)"
      ],
      "metadata": {
        "id": "3sfdfk-AsSJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 앙상블 Retriever\n",
        "from langchain.retrievers import EnsembleRetriever\n",
        "from langchain.retrievers.document_compressors import LengthBasedDocumentCompressor\n",
        "from langchain.retrievers.document_compressors import LLMChainCompressor\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "\n",
        "# BM25 리트리버 생성\n",
        "#k1:용어빈도 중요도, b:문서길이 중요도\n",
        "bm25_retriever = BM25Retriever(\n",
        "    collection=docsearch.as_retriever().get_relevant_documents,\n",
        "    search_kwargs={'k1': 1.2, 'b': 0.75}\n",
        ")\n",
        "\n",
        "# 임베딩 기반 (문서 검색) 리트리버 생성\n",
        "# 문서 검색 기능 제공 객체에서 관련 문서 가져옴\n",
        "# search_k = 최근접 이웃 수, k=3 = k개의 관련성 높은 문서 반환\n",
        "faiss_retriever = FaissRetriever(\n",
        "    collection=docsearch.as_retriever().get_relevant_documents,\n",
        "    search_k=50\n",
        "    k=5\n",
        ")\n",
        "\n",
        "# 리트리버 리스트 생성\n",
        "retrievers = [bm25_retriever, faiss_retriever]\n",
        "\n",
        "# 문서 압축기 생성 (선택 사항)\n",
        "# compressor = LLMChainCompressor(llm=OpenAI(temperature=0.5))\n",
        "\n",
        "# Ensemble Retriever 생성\n",
        "ensemble_retriever = EnsembleRetriever(\n",
        "    retrievers=retrievers,\n",
        "    # document_compressor=compressor\n",
        ")\n",
        "\n",
        "# Streaming 출력을 위한 콜백 핸들러 생성\n",
        "callback_handler = StreamingStdOutCallbackHandler()\n",
        "\n",
        "# RetrievalQA 생성\n",
        "# \"stuff\": 검색된 문서를 연결하여 응답 생성 방식\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=OpenAI(temperature=0.5, callbacks=[callback_handler]),\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=ensemble_retriever,\n",
        "    return_source_documents=True  #원본 문서도 함께 반환\n",
        ")\n",
        "\n",
        "# 질문 실행\n",
        "query = \"\"\n",
        "result = qa(query)"
      ],
      "metadata": {
        "id": "XQVf74ECsTOj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}